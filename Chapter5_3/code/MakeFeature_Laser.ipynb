{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf89aeb-efc2-4baf-8489-7a78f1a20f18",
   "metadata": {},
   "source": [
    "# 散乱強度・距離の補正\n",
    "- プロファイル関連の特徴量が変化\n",
    "- 画像特徴量は変化なしなので、今回は生成しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bea1c1f-211c-4005-97a8-0dcdf10388a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit, minimize_scalar\n",
    "from scipy import signal\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from FuncLaserScattering import delete_distance, smoothing_apple, skip_distance, correct_intensity, correct_distance\n",
    "from FuncLaserScattering import fitting, calc_diff, image2feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4752795a-fcc5-4579-a2eb-aee6c10c1df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start image analysis!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:55\u001b[0m\n",
      "File \u001b[0;32m~/python_enviroment/MasterDegree/Chapter5_3/code/FuncLaserScattering.py:414\u001b[0m, in \u001b[0;36mimage2feature\u001b[0;34m(path_folder)\u001b[0m\n\u001b[1;32m    411\u001b[0m temp_sfm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(features,index\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# Law's Texture Energy Measures (LTE/TEM, 6個)\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m features, labels \u001b[38;5;241m=\u001b[39m \u001b[43mpyfeats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlte_measures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_del_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_texture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m temp_lte \u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mDataFrame(features,index\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Fractal Dimension Texture Analysis (FDTA, 4個)\u001b[39;00m\n",
      "File \u001b[0;32m~/python_enviroment/MasterDegree/.venv/lib/python3.10/site-packages/pyfeats/textural/lte.py:79\u001b[0m, in \u001b[0;36mlte_measures\u001b[0;34m(f, mask, l)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# 4) Get mask where convolution should be performed\u001b[39;00m\n\u001b[1;32m     78\u001b[0m mask_c \u001b[38;5;241m=\u001b[39m _image_xor(mask)\n\u001b[0;32m---> 79\u001b[0m mask_conv \u001b[38;5;241m=\u001b[39m \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moneskernel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m mask_conv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39msign(mask_conv)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# 5) Calculate energy of each convolved image with each kernel: total 9\u001b[39;00m\n",
      "File \u001b[0;32m~/python_enviroment/MasterDegree/.venv/lib/python3.10/site-packages/scipy/signal/_signaltools.py:1752\u001b[0m, in \u001b[0;36mconvolve2d\u001b[0;34m(in1, in2, mode, boundary, fillvalue)\u001b[0m\n\u001b[1;32m   1750\u001b[0m val \u001b[38;5;241m=\u001b[39m _valfrommode(mode)\n\u001b[1;32m   1751\u001b[0m bval \u001b[38;5;241m=\u001b[39m _bvalfromboundary(boundary)\n\u001b[0;32m-> 1752\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43m_sigtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolve2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfillvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 新しい解析法で得られたデータで特徴量作成\n",
    "# 粉質化のみの算出\n",
    "for condition in ['FirstStorage','SecondStorage']:\n",
    "    for storage in tqdm(['00','01','02','03','04']):\n",
    "        for wave in ['633','850']:\n",
    "\n",
    "            ##### データの読み込み #####\n",
    "            total_df = pd.read_csv(f'./../data/data_{condition}/data_laser/Profile_new_data/{wave}nm/Profile_{condition}_{storage}_{wave}nm.csv')\n",
    "\n",
    "            # 距離と輝度（強度）を分割\n",
    "            distance = total_df.iloc[:,0]\n",
    "            apple_df = total_df.drop('distance (mm)',axis=1)\n",
    "\n",
    "\n",
    "            #####解析範囲外の領域を削除#####\n",
    "            distance_30mm, apple_df_30mm = delete_distance(distance, apple_df)\n",
    "          \n",
    "            #####散乱距離の補正#####\n",
    "            distance_30mm = correct_distance(distance_30mm)\n",
    "            \n",
    "            #####散乱強度の補正#####\n",
    "            apple_df_30mm = correct_intensity(distance_30mm,apple_df_30mm)\n",
    "\n",
    "            #####プロファイルの平滑化#####\n",
    "            distance_smooth, apple_smooth = smoothing_apple(distance_30mm, apple_df_30mm)\n",
    "\n",
    "            #####プロファイルの間引き (1mm間隔)#####\n",
    "            distance_eq, apple_smooth_eq = skip_distance(distance_smooth, apple_smooth)\n",
    "\n",
    "\n",
    "            #####変化率の取得#####\n",
    "            res = calc_diff(distance_eq, data_smoothing=apple_smooth_eq)\n",
    "\n",
    "            #####CurveFitting#####\n",
    "            eff_df = pd.DataFrame()\n",
    "\n",
    "            distance_eq = distance_eq[1:]\n",
    "            apple_smooth_eq = apple_smooth_eq.iloc[1:,:]\n",
    "\n",
    "            for i in range(apple_smooth_eq.shape[1]): \n",
    "\n",
    "                eff_temp = fitting(distance_eq,apple_smooth_eq.iloc[:,i])\n",
    "\n",
    "                eff_df = pd.concat([eff_df,eff_temp],axis=0)\n",
    "\n",
    "            eff_df.index = res.columns\n",
    "\n",
    "            # 結合の都合上転置する\n",
    "            eff_df = eff_df.T\n",
    "            \n",
    "             #####画像から特徴量を抽出#####\n",
    "            print('start image analysis!!!')\n",
    "\n",
    "            image_path = f'./../data/data_{condition}/data_laser/HDRimage/Original_func/{condition}/{wave}nm/week{storage}'\n",
    "            feature_img = image2feature(image_path)\n",
    "            feature_img.index = res.columns\n",
    "\n",
    "\n",
    "            #####全特徴量の結合および保存#####\n",
    "            feature_df = pd.concat([eff_df, res, feature_img.T],axis=0).T\n",
    "            \n",
    "            \n",
    "\n",
    "            ##### データの保存 #####\n",
    "            # 平滑化後のプロファイルおよび特徴量を保存\n",
    "            apple_smooth_eq.to_csv(f'./../data/data_{condition}/data_laser/smoothing/smoothing_CB_CorrectBoth/{wave}nm/Smooth_{storage}.csv')\n",
    "            feature_df.to_csv(f'./../data/data_{condition}/data_laser/feature/feature_CB_HDR/feature_all/{wave}nm/feature_{storage}.csv')\n",
    "\n",
    "            # 分析用にindexを分ける\n",
    "            index_All = pd.Series(feature_df.index)\n",
    "            index_Shake = index_All[index_All.str.endswith(('_2','_4'))].tolist()\n",
    "\n",
    "            # texture推定用に加工した特徴量dataframeを保存\n",
    "            # XX_X_1, XX_X_3となっているサンプルはテクスチャー推定用に保存\n",
    "            temp = feature_df.drop(index_Shake,axis=0)\n",
    "            temp.to_csv(f'./../data/data_{condition}/data_laser/feature/feature_CB_HDR/feature_texture/{wave}nm/feature_{storage}.csv')\n",
    "\n",
    "            # XX_X_2, XX_X_4となっているサンプルは用意果肉ディスク振とう用に保存\n",
    "            temp = feature_df.loc[index_Shake,:]\n",
    "            temp.to_csv(f'./../data/data_{condition}/data_laser/feature/feature_CB_HDR/feature_shake/{wave}nm/feature_{storage}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2857b696-9ea6-4b07-8391-dffcdce90a2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "850nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "633nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "850nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "633nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "850nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "633nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "850nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "633nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "850nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "633nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "850nmにおける結合するcsvファイル ['feature_00.csv', 'feature_01.csv', 'feature_02.csv', 'feature_03.csv', 'feature_04.csv']\n",
      "\n",
      "\n",
      "633nmにおける結合するcsvファイル ['Smooth_00.csv', 'Smooth_01.csv', 'Smooth_02.csv', 'Smooth_03.csv', 'Smooth_04.csv']\n",
      "850nmにおける結合するcsvファイル ['Smooth_00.csv', 'Smooth_01.csv', 'Smooth_02.csv', 'Smooth_03.csv', 'Smooth_04.csv']\n",
      "633nmにおける結合するcsvファイル ['Smooth_00.csv', 'Smooth_01.csv', 'Smooth_02.csv', 'Smooth_03.csv', 'Smooth_04.csv']\n",
      "850nmにおける結合するcsvファイル ['Smooth_00.csv', 'Smooth_01.csv', 'Smooth_02.csv', 'Smooth_03.csv', 'Smooth_04.csv']\n"
     ]
    }
   ],
   "source": [
    "# 貯蔵期間ごとの特徴量を１つにまとめる #####\n",
    "\n",
    "for condition in ['FirstStorage','SecondStorage']:\n",
    "    for folder in ['feature_all','feature_texture','feature_shake']:\n",
    "        for wavelen in [\"633nm\",\"850nm\"]:\n",
    "\n",
    "            allfile = os.listdir(f'./../data/data_{condition}/data_laser/feature/feature_CB_HDR/{folder}/{wavelen}')\n",
    "            csv_list = [csvfile for csvfile in allfile if 'feature' in csvfile]\n",
    "            csv_list = [csvfile for csvfile in csv_list if 'all' not in csvfile]\n",
    "            csv_list.sort()\n",
    "            # csv_list.pop(0)\n",
    "            print(f'{wavelen}における結合するcsvファイル',csv_list)\n",
    "\n",
    "            # 特徴量を結合\n",
    "            profile_all = pd.DataFrame()\n",
    "            for csv_path in csv_list:\n",
    "                df_temp = pd.read_csv(f'./../data/data_{condition}/data_laser/feature/feature_CB_HDR/{folder}/{wavelen}/{csv_path}',\n",
    "                                      header=0,\n",
    "                                      index_col=0)\n",
    "                profile_all = pd.concat([profile_all, df_temp],axis=0)\n",
    "\n",
    "            # 特徴量を保存\n",
    "            feature_all = profile_all\n",
    "            feature_all.to_csv(f'./../data/data_{condition}/data_laser/feature/feature_CB_HDR/{folder}/{wavelen}/feature_all.csv')\n",
    "\n",
    "print()\n",
    "print()\n",
    "##### 貯蔵期間ごとのprofileを１つにまとめる #####\n",
    "for condition in ['FirstStorage','SecondStorage']:\n",
    "    for wavelen in [\"633nm\",\"850nm\"]:\n",
    "\n",
    "        allfile = os.listdir(f'./../data/data_{condition}/data_laser/smoothing/smoothing_CB_CorrectBoth/{wavelen}')\n",
    "        csv_list = [csvfile for csvfile in allfile if 'Smooth' in csvfile]\n",
    "        csv_list = [csvfile for csvfile in csv_list if 'all' not in csvfile]\n",
    "        csv_list.sort()\n",
    "        # csv_list.pop(0)\n",
    "        print(f'{wavelen}における結合するcsvファイル',csv_list)\n",
    "\n",
    "        # 特徴量を結合\n",
    "        profile_all = pd.DataFrame()\n",
    "        for csv_path in csv_list:\n",
    "            df_temp = pd.read_csv(f'./../data/data_{condition}/data_laser/smoothing/smoothing_CB_CorrectBoth/{wavelen}/{csv_path}',\n",
    "                                  header=0,\n",
    "                                  index_col=0)\n",
    "            profile_all = pd.concat([profile_all, df_temp],axis=1)\n",
    "\n",
    "        # 特徴量を保存\n",
    "        profile_all.to_csv(f'./../data/data_{condition}/data_laser/smoothing/smoothing_CB_CorrectBoth/{wavelen}/Smooth_all.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5588ce7-d185-49e1-a30b-d48fc2d228de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
